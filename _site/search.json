[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fábio P. Fortkamp’s professional website",
    "section": "",
    "text": "How to maintain a codebase compatible with Python 2 and 3 at the same time using tox\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nJul 11, 2024\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nWhere’s the literature on object-oriented programming with Python?\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nIDE or Neovim - why not both?\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nJun 21, 2024\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nHigher productivity for developers with Starship\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Development Book Review: Writing Interpreters in Go\n\n\n\n\n\n\nbook-recommendations\n\n\nlearning-interpreters-and-compilers\n\n\n\n\n\n\n\n\n\nApr 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nStudying Go to get better at Python: reader and writer interfaces\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nApr 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHow to make Neovim Python LSP aware of your Hatch environments\n\n\n\n\n\n\narticles\n\n\nconfiguring-neovim-for-maximum-productivity\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWhy I’m studying how to write an interpreter in Go… when I’m a Python developer\n\n\n\n\n\n\narticles\n\n\nbook-recommendations\n\n\nlearning-interpreters-and-compilers\n\n\nwhat-im-studying\n\n\n\n\n\n\n\n\n\nMar 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWhy and how to use different colors in VS Code for different projects\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nDec 21, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nI’m a Python developer - and this is why I’m learning Julia\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nDec 13, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nWhy a mechanical engineer uses Linux - in Windows\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nDec 2, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nCompressibility and Expandability: what are they and how to calculate\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nNov 10, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nStages of studying: 1 - Inspectional Reading\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nNov 9, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\n3 things missing from the Mechanical Engineering curriculum\n\n\n\n\n\n\nLists\n\n\n\n\n\n\n\n\n\nNov 8, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nIncluding superheat in the compressor regression\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nApr 20, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nExploring and regressing data from a compressor datasheet with Python\n\n\n\n\n\n\nArticles\n\n\n\n\n\n\n\n\n\nApr 19, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Law Analysis of a Mixture of Non-Ideal Gases - Exercise 13-99 from Çengel's Thermodynamics book (7th ed)\n\n\n \n\n\nExercise from Çengel's Thermodynamics\n\n\n \n\n\n\n\n\n`Mar 18, 2022`{=html}\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalculting equilibrium composition of a mixture of gases - Exercise 16-89 from Çengel's Thermodynamics book (7th ed)\n\n\n \n\n\nExercise from Çengel's Thermodynamics\n\n\n \n\n\n\n\n\n`Mar 17, 2022`{=html}\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Law Analysis of a Mixture of Ideal Gases - Exercise 13-97 from Çengel's Thermodynamics book (7th ed)\n\n\n \n\n\nExercise from Çengel's Thermodynamics\n\n\n \n\n\n\n\n\n`Mar 15, 2022`{=html}\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing the work of a mixture of gases - Exercises 13-94 and 13-95 from Çengel's Thermodynamics book\n\n\n \n\n\nExercise from Çengel's Thermodynamics\n\n\n \n\n\n\n\n\n`Mar 15, 2022`{=html}\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeed of sound of a mixture of gases - Exercise 13-92 from Çengel's Thermodynamics book (7th ed)\n\n\n \n\n\nExercise from Çengel's Thermodynamics\n\n\n \n\n\n\n\n\n`Mar 14, 2022`{=html}\nFábio P. Fortkamp\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is this site\n\n\n\n\n\n\nNotes\n\n\n\n\n\n\n\n\n\nFeb 27, 2022\n\n\nFábio P. Fortkamp\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "My Portfolio of Programming Projects",
    "section": "",
    "text": "I’m currently employed as a Mechanical/Research Engineer in a research group in southern Brazil, and my main responsibility is developing applications and libraries for use of one of Brazil’s largest oil & gas software. Our main products is a wellbore simulator and a thermophysical properties library. Both are used by end users in a web app (that is developed by a third-party).\nMy main working language in this position is Python, mainly for faciliting collaborating with other engineers, researchers, and especially students. I’ve been using Python since 2011 and I consider myself very profficient in it, in particular with the scientific stack: NumPy, SciPy, and Matplotlib. I’m also very familiar developing command line applications with Typer and Rich, managing projects with tox and hatch, and testing with pytest.\nMy main projects are private, but some work-related open-source projects include:\n\nscientific-python2.7-docker: a Docker image with Python 2.7 and scientific libraries installed on top of it (our properties library is implemented in Python 2.7 for use in a legacy server)\ntissues: a helper utility that runs a linter of your choice, and then fails not if there is an issue, but if the number of issues has not decreased from the previous run. This is useful for forcing yourself to incrementally improve a legacy codebase, where eliminating all linter issues in one take is not viable"
  },
  {
    "objectID": "portfolio.html#current-job",
    "href": "portfolio.html#current-job",
    "title": "My Portfolio of Programming Projects",
    "section": "",
    "text": "I’m currently employed as a Mechanical/Research Engineer in a research group in southern Brazil, and my main responsibility is developing applications and libraries for use of one of Brazil’s largest oil & gas software. Our main products is a wellbore simulator and a thermophysical properties library. Both are used by end users in a web app (that is developed by a third-party).\nMy main working language in this position is Python, mainly for faciliting collaborating with other engineers, researchers, and especially students. I’ve been using Python since 2011 and I consider myself very profficient in it, in particular with the scientific stack: NumPy, SciPy, and Matplotlib. I’m also very familiar developing command line applications with Typer and Rich, managing projects with tox and hatch, and testing with pytest.\nMy main projects are private, but some work-related open-source projects include:\n\nscientific-python2.7-docker: a Docker image with Python 2.7 and scientific libraries installed on top of it (our properties library is implemented in Python 2.7 for use in a legacy server)\ntissues: a helper utility that runs a linter of your choice, and then fails not if there is an issue, but if the number of issues has not decreased from the previous run. This is useful for forcing yourself to incrementally improve a legacy codebase, where eliminating all linter issues in one take is not viable"
  },
  {
    "objectID": "portfolio.html#side-projects",
    "href": "portfolio.html#side-projects",
    "title": "My Portfolio of Programming Projects",
    "section": "Side Projects",
    "text": "Side Projects\nI love learning new languages and I’ve been making a point of creating some projects to showcase what I’ve learned. Since my expertise is in scientific- and text-oriented command-line applications, my latest interests are Rust and Go.\nSome of my non-Python projects:\n\nbln - a simplified version of the Unix ln command, written in Go, and that uses flags instead of arguments (I can never remember the order of arguments in ln).\nengsymbols - a LaTeX package to facilitate writing complex engineering symbols\n\nSee also my dotfiles and my neovim configuration."
  },
  {
    "objectID": "portfolio.html#open-source-contributions",
    "href": "portfolio.html#open-source-contributions",
    "title": "My Portfolio of Programming Projects",
    "section": "Open-source contributions",
    "text": "Open-source contributions\nI’m learning how to better contribute to open-source projects. Some projects that I’ve contributed in the past are:\n\nprm -a Bash project manager\nDrWatson - a Julia scientific project manager"
  },
  {
    "objectID": "post/ide/index.html",
    "href": "post/ide/index.html",
    "title": "IDE or Neovim - why not both?",
    "section": "",
    "text": "It’s not a secret that I love Neovim. Using a terminal-based, powerful editor allows me to write new code very fast, allowing myself to get into a state of flow and transfering my ideas to the code. With its powerful motions, shortcuts, and LSP support, I can quickly add new functions, move things around, indent and outdent code (particularly relevant for Python code). And using side-by-side with tmux, I can edit some code, switch to the terminal and run some tests, go back to the code for more editing…\nAnd yet, today was one of those days in which I worked only in an IDE. PyCharm, to be more specific.\nI don’t know if I can pinpoint exactly which I use both Neovim and an IDE. Partly is to get some novelty and break out of boredom, for sure. But I’m realizing that these code-editing programs have different purposes:\nThe Fábio Fortkamp theory of code editors:\n\nNeovim (or any regular text editor) is for adding new code\nIDEs are for refactoring and structuring existing code\n\nI love the automated refactoring capabilities of the JetBrains IDEs. Yes, there’s a refactoring plugin by the legend himself, but when in this headspace I just want to use the mouse, you know? Open a file in the file explorer, select some text, pause and think about, see the options in a menu - in short, have the IDE guide me.\n\n\n\nSelecting an automated refactoring in PyCharm\n\n\nThere’s a more subtle effect that I find it even harder to describe, and it was something that was reminded to me in my morning run listening to this MPU episode when Neil Jhaveri was talking the very symbolic moment when he sat down and created the XCode project for Apple Notes. Yes, with tmux sessions you can delimit the context in which you are working, with each pane or window pointing to a specific folder, and when you are done you simply detach from a session, but for me opening a PyCharm IDE has a very strong meaning: for the next hour and a half, I’m working on this big Python project that need automated editing.\nSo yes, I use Neovim all the time; I have my config, I use beautiful themes, I follow the right NeoVim creators. But this is not a cult, and I like to keep my IDE ready when I need it."
  },
  {
    "objectID": "post/compressor/index.html",
    "href": "post/compressor/index.html",
    "title": "Exploring and regressing data from a compressor datasheet with Python",
    "section": "",
    "text": "When selecting a compressor for a refrigeration system, the engineer usually has to browse through datasheets to select the most appropriate machine. The user must select a compressor that works with the selected refrigerant (chosen for environmental and cost reasons) and is able to deliver the required cooling capacity when operating between evaporating and condensing temperatures; these are linked to the cold and hot source temperatures (that is, the low temperature that is to maintained and the hot ambient temperature over which we have no control) through heat exchangers, but for this text we will ignore that and assume ideal heat exchangers.\nHere is one example of a compressor datasheet that we will explore in this post. The main data is presented in tables of various metrics as a function of evaporating temperature, and we have one table for each condensing temperature like this:\nThis must be converted to a text format. After a recomendation from Dr. Drang, I often use Tabula: this app allows you to upload PDFs and extract a text table from it:\nThe result can be downloaded as a CSV and cleaned up; it is also useful to explicitly include the condensing temperature as a column, in the case we want to generalize the results of this post to other temperatures:\nThis can be parsed with pandas:\nimport pandas as pd\n\ndf = pd.read_csv(\"compressor.csv\",delimiter=',')\nprint(df)\n\n   Evaporating Temperature [C]  Condensing temperature [C]  \\\n0                          -35                          35   \n1                          -30                          35   \n2                          -25                          35   \n3                          -20                          35   \n4                          -15                          35   \n5                          -10                          35   \n\n   Cooling Capacity [W]  Power [W]  Current [A]  Gas Flow Rate [kg/h]  \\\n0                   167        129         1.21                  1.79   \n1                   218        144         1.23                  2.34   \n2                   282        160         1.27                  3.03   \n3                   362        177         1.32                  3.89   \n4                   457        197         1.38                  4.93   \n5                   570        217         1.45                  6.16   \n\n    Efficiency [W/W]  \n0               1.29  \n1               1.52  \n2               1.77  \n3               2.04  \n4               2.33  \n5               2.63"
  },
  {
    "objectID": "post/compressor/index.html#how-to-calculate-the-mass-flow-rate-of-a-compressor",
    "href": "post/compressor/index.html#how-to-calculate-the-mass-flow-rate-of-a-compressor",
    "title": "Exploring and regressing data from a compressor datasheet with Python",
    "section": "How to calculate the mass flow rate of a compressor?",
    "text": "How to calculate the mass flow rate of a compressor?\nA reciprocating compressor like this one is a volumetric machine: it displaces a certain volume of fluid, based on its internal geometry, and the mass flow rate depends on the suction state.\nThe most basic, ideal model is then:\n\\[\n\\dot{m} = \\frac{\\dot{\\mathcal{V}} _{\\mathrm{D}}}{v _{\\mathrm{in}}}\n\\]\nwhere the numerator is the displacement rate; for a compressor with \\(z\\) cylinders at a fixed rotation speed \\(n\\) it can be calculated\n\\[\n\\dot{\\mathcal{V}} _{\\mathrm{D}} = {\\mathcal{V}} _{\\mathrm{D}} n z\n\\]\nwhere \\(\\mathcal{V} _{\\mathrm{D}}\\) is the internal displacement.\nLet’s plot the actual mass flow rate from the datasheet (using the geometric parameters from it) and the above model to compare:\n\nimport matplotlib.pyplot as plt\nfrom CoolProp.CoolProp import PropsSI\nimport numpy as np\n\nplt.rc('font', size=14)\n\nVd = 13.54e-6 # in m3\nn = 60 #Hz\nz = 1\nfluid = 'R600a'\n\nVd_dot = Vd * n * z # m3/s\nT_evap = df[\"Evaporating Temperature [C]\"].values\nm_dot_actual = df[\"Gas Flow Rate [kg/h]\"].values\n\n# we take the inverse of the density \n# of saturated vapor (quality = 1)\n# at each value of evaporating temperature\n# not forgetting to convert to K for CoolProp\nv_in = np.array([(1.0/PropsSI(\"D\",\"T\",Te + 273,\"Q\",1,fluid)) for Te in T_evap])\nm_dot_ideal = 3600*Vd_dot/v_in\n\nfig, ax = plt.subplots()\nax.plot(T_evap,m_dot_ideal,'k-',label=\"Ideal\")\nax.plot(T_evap,m_dot_actual,'ko',label=\"Actual\")\nax.set_xlabel(\"Evaporating temperature [ºC]\")\nax.set_ylabel(\"Gas flow rate [kg/h]\")\nax.set_title(\n\"\"\"R-600a compressor, 60 Hz, 1 cylinder, displacement = %.2f cm3, \ncondensing temperature = %d ºC\"\"\" %(Vd*1e6, df[\"Condensing temperature [C]\"].values[0]),\nloc='left')\nax.legend()\nax.grid()\nplt.show()\n\n\n\n\n\n\n\n\nClearly our model is not good enough! There is a volumetric efficiency that is influenced by dead volumes and leakages:\n\\[\n\\eta_{\\mathrm{v}} = \\frac{\\dot{m}}{\\frac{\\dot{\\mathcal{V}} _{\\mathrm{D}}}{v _{\\mathrm{in}}}}\n\\]:\n\neta_v = m_dot_actual/m_dot_ideal*100\nfig2, ax2 = plt.subplots()\n\nax2.plot(T_evap,m_dot_actual,'ko',label=\"Actual mass flow rate\")\nax2.set_xlabel(\"Evaporating temperature [ºC]\")\nax2.set_ylabel(\"Gas flow rate [kg/h] (dots)\")\nax2.set_title(\n\"\"\"R-600a compressor, 60 Hz, 1 cylinder, displacement = %.2f cm3, \ncondensing temperature = %d ºC\"\"\" %(Vd*1e6, df[\"Condensing temperature [C]\"].values[0]),\nloc='left')\n\nax3 = ax2.twinx()\nax3.plot(T_evap,eta_v,'kx',label=\"Volumetric efficiency\")\nax3.set_ylabel(\"Volumetric efficiency [%%] (x)\")\nax2.grid()\n\nplt.show()"
  },
  {
    "objectID": "post/compressor/index.html#polynomials-for-cooling-capacity",
    "href": "post/compressor/index.html#polynomials-for-cooling-capacity",
    "title": "Exploring and regressing data from a compressor datasheet with Python",
    "section": "Polynomials for cooling capacity",
    "text": "Polynomials for cooling capacity\nThe other useful thing to do with a compressor datasheet of calculating a polynomial of the form [1]:\n\\[\n\\dot{Q} _{\\mathrm{L}} = a _0 + a _1  t _{\\mathrm{evap}} + a _2  t _{\\mathrm{evap}}^2\n\\]\nwhere \\(\\dot{Q}_{\\mathrm{L}}\\) is the cooling capacity and \\(t_{\\mathrm{evap}}\\) is the evaporating temperature in degress Celsius. Three points of note:\n\nThis polynomial allows you to interpolate in different points other than the tabulated ones, an also can be combined with other models in the refrigeration system;\nThe coefficients themselves are function of the condensing temperature, the fluid properties and the compressor geometry;\nThe same thing can be done for the power consumption, with different coefficients.\n\nWe will use scikit-learn to train a model to calculate the coefficients, based on 50% of the data selected at random:\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\n\nX = df.values[:,:1] # first column (evaporating temperature) as a 2D array, as required\nYQL = df[\"Cooling Capacity [W]\"].values\n\nX_train,X_test,QL_train,QL_test = train_test_split(X,YQL,test_size=0.5)\n\nQL_quadratic_model = Pipeline(\n[\n('poly', PolynomialFeatures(degree=2)),\n('linear', LinearRegression(fit_intercept=False))])\nQL_quadratic_model.fit(X_train, QL_train)\nQL_quadratic_pred = QL_quadratic_model.predict(X_test)\n\nfig4, ax4 = plt.subplots()\nax4.scatter(QL_test,QL_quadratic_pred)\nax4.grid()\nax4.set_xlabel('Simulated cooling capacity [W]]')\nax4.set_ylabel('Predicted cooling capacity [W]')\nax4.set_title('accuracy (R^2) =  %.5f'\n% r2_score(QL_test, QL_quadratic_pred))\nplt.show()\n\n\n\n\n\n\n\n\nThe resulting coefficients are (from \\(a_0\\) to \\(a_2\\)):\n\nprint(QL_quadratic_model.named_steps[\"linear\"].coef_)\n\n[8.42e+02 3.04e+01 3.20e-01]\n\n\nHence, this polynomial seems to work fine, even though we have very few data points; with more data points in a test apparatus, this same model could be retrained, making the coefficients more and more accurate.\nThe advantage of this approach is that, if we are working with this compressor and selecting heat exchangers sizes, for instance, we do not need to evaluate thermophysical properties at each iteration but only a polynomial, which is a huge time saver. How to make this integration between models is the subject of another post.\nUPDATE: there’s a follow-up post which corrects some mistakes that you should read now."
  },
  {
    "objectID": "post/compressor/index.html#references",
    "href": "post/compressor/index.html#references",
    "title": "Exploring and regressing data from a compressor datasheet with Python",
    "section": "References",
    "text": "References\n[1]: Stoecker, W. F. Design of thermal systems. [sl]: McGraw-Hill, 1980."
  },
  {
    "objectID": "post/isothermic/index.html",
    "href": "post/isothermic/index.html",
    "title": "Computing the work of a mixture of gases - Exercises 13-94 and 13-95 from Çengel’s Thermodynamics book",
    "section": "",
    "text": "In the previous post, we saw how to calculate the speed of sound of a mixture of ideal gases, the main assumption is that we can add the individual specific heats of the components, weighted by the mass fractions.\nFor mixtures of ideal gases, this is true for all mass-specific properties, including the gas constant \\(R\\). Hence, basic First-Law analyses can be performed quite easily."
  },
  {
    "objectID": "post/isothermic/index.html#an-example-of-isothermic-work",
    "href": "post/isothermic/index.html#an-example-of-isothermic-work",
    "title": "Computing the work of a mixture of gases - Exercises 13-94 and 13-95 from Çengel’s Thermodynamics book",
    "section": "An example of isothermic work",
    "text": "An example of isothermic work\nThe specific work required to compress an ideal gas in a closed system [1] isothermally at \\(T\\) from pressure \\(P_1\\) to \\(P_2\\) is [1]:\n\\[\nw_{\\mathrm{comp}} = R T \\ln \\frac{P_2}{P_1}\n\\]\nThis is also valid for a mixture of ideal gases, provided the mixture gas constant is used:\n\\[\nR = \\frac{R_u}{M_{\\mathrm{m}}}\n\\]\nwhere \\(R_u = 8.31447\\,\\mathrm{kJ/kg K}\\) is the universal gas constant and the mixture molar mass is:\n\\[\nM_{\\mathrm{m}} = \\sum_{i=1}^k y_i M_i\n\\]\nsumming over \\(k\\) components, and there \\(y_i\\) and \\(M_i\\) are the individual molar fractions and molar mass of component \\(i\\), respectively.\nConsider exercise 13-94 from [1]: the mixture contains 85% of nitrogen gas, and the remainder is carbon dioxide. The temperature is held at 300 K and the pressure is risen from 100 kPa to 500 kPa. What is the compression work?\nThe following implementation is in R. We first define a function to compute the desired value based on the initial content of nitrogen:\n\nwork.N2.CO2 &lt;- function(yN2) {\n  MN2 &lt;- 28.013\n  MCO2 &lt;- 44.01\n  Ru &lt;-  8.13447\n  T &lt;- 300\n  P1 &lt;- 100\n  P2 &lt;- 500\n  \n  Mm &lt;- yN2*MN2 + (1-yN2)*MCO2\n  R = Ru/Mm\n  \n  wcomp &lt;- R*T*log(P2/P1)\n  wcomp\n}\n\nLet’s check with the individual given value:\n\nprint(work.N2.CO2(0.85))\n\n[1] 129.1433\n\n\nNotice that this value is in kJ/kg.\nNow, let’s see how this varies with nitrogen content:\n\ncurve(work.N2.CO2,from=0,to=1)\n\n\n\n\n\n\n\n\nThe more nitrogen we have, the larger the work. Why is that? Nitrogen is lighter (compare the molar masses), so with more nitrogen the mixture molar mass decreases, but that increases the gas constant and hence the specific work. The overall volume variations increase with a lighter gas, increasing the required work to increase the pressure."
  },
  {
    "objectID": "post/isothermic/index.html#an-example-of-isentropic-work",
    "href": "post/isothermic/index.html#an-example-of-isentropic-work",
    "title": "Computing the work of a mixture of gases - Exercises 13-94 and 13-95 from Çengel’s Thermodynamics book",
    "section": "An example of isentropic work",
    "text": "An example of isentropic work\nNow we examine Exercise 13-95 from [1], where are given directly the mixture molar mass of 32 kg/kmol and a specific heat ratio of 1.35; as we’ve discussed, these are obtained from weighted sums. The initial state is 100 kPa and 293 K, the final pressure 1000 kPa, and the process occurs at constant entropy. What is the work?\nThe compression work of an ideal gas in an isentropic process is:\n\\[\nw_{\\mathrm{comp}} = \\frac{R T_1}{k-1} \\left[\\left(\\frac{P_2}{P_1}\\right)^{{\\frac{k-1}{k}}}-1\\right]\n\\] Can we use this expression of a single ideal gas for a mixture of ideal gases? Again yes, provide we use the mixture properties, which are already given. Notice that the mixture gas constant is not given but can be calculated similarly as above. Hence:\n\nk &lt;-  1.35\nMm &lt;- 32\nRu &lt;-  8.13447\nR &lt;- Ru/Mm \n\nP1 &lt;- 100\nP2 &lt;- 1000\nT1 &lt;- 293\n\n# some intermediate parameters to facilitate writing\nPi = P2/P1\ngamma = ((k-1)/k)\nY = Pi^gamma - 1\n\nwcomp &lt;- (R*T1)/(k-1) * Y\nprint(wcomp) # in kJ/kg\n\n[1] 173.7753\n\n\nTo compare, we can also compute the work by temperature variations. An isentropic process follows \\[\n\\frac{T_2}{T_1} = \\left(\\frac{P_2}{P_1}\\right)^{\\frac{k-1}{k}}\n\\]\nand, in an adiabatic closed-system process:\n\\[\nw_{\\mathrm{comp}} = c_v(T_2-T_1)\n\\]\nwhere \\(c_v = \\frac{R}{k-1}\\).\n\nk &lt;-  1.35\nMm &lt;- 32\nRu &lt;-  8.13447\nR &lt;- Ru/Mm \n\nP1 &lt;- 100\nP2 &lt;- 1000\nT1 &lt;- 293\n\nT2 &lt;- T1*(P2/P1)^((k-1)/k)\ncv &lt;- R/(k-1)\nwcomp &lt;- cv*(T2-T1)\nprint(wcomp)\n\n[1] 173.7753\n\n\nAnd the values match."
  },
  {
    "objectID": "post/isothermic/index.html#references",
    "href": "post/isothermic/index.html#references",
    "title": "Computing the work of a mixture of gases - Exercises 13-94 and 13-95 from Çengel’s Thermodynamics book",
    "section": "References",
    "text": "References\n[1]: Çengel, Y. A., & Boles, M. A. Termodinâmica (7 ed.). Porto Alegre: AMGH, 2013. In Portuguese."
  },
  {
    "objectID": "post/real/index.html",
    "href": "post/real/index.html",
    "title": "First Law Analysis of a Mixture of Non-Ideal Gases - Exercise 13-99 from Çengel’s Thermodynamics book (7th ed)",
    "section": "",
    "text": "In a previous post, we performed a First-Law Analysis, calculating work and heat transfer, of a mixture of ideal gases.\nNow we have a more realistic situation, taken from Exercise 13-99 from [1]: a mixture of 4 kg of \\(\\mathrm{He}\\) and 8 kg of \\(\\mathrm{O_2}\\) is kept in a rigid tank initially at 170 K and 7 MPa and pressure. The tank is then heated up to 220 K. What is the final pressure and the heat transfer during this process, assuming that helium is an ideal gas but oxygen is not?\nWe have two things in consideration here: first, as the oxygen is not itself is an ideal gas, its molecules will interact with each other in a way that the ideal gas model (which assumes molecules completely ignorant of the presence of other molecules, with no attraction or repulsion forces mainly) cannot predict; but second, how will the molecules of different gases interact. In other words: will the molecules of oxygen suffer forces from helium molecules as well?\nI’ll take the middle way here and use ideal gas mixture rules for non-ideal gases. The mixture is approximately a mixture of ideal gases, with little interaction between different components, but the individual behavior of the components will follow different rules.\nIndependent of the equation of state, we can start by calculating the composition of the mixture in different bases. From the given mass values, the mass fraction of helium is \\(x_{\\mathrm{He}} = \\frac{1}{3}\\) and of oxygen is \\(x_{\\mathrm{O_2}} = \\frac{2}{3}\\). The total mass is \\(m = 12\\,\\mathrm{kg}\\). Each of the \\(n\\) components has its molar mass \\(M_i\\), and the mixture molar mass can be calculated as:\n\\[\nM_{\\mathrm{m}} = \\frac{1}{\\sum_{i=1}^n \\frac{x_i}{M_i}}\n\\]\nThe mixture gas constant is:\n\\[\nR_{\\mathrm{m}} = \\frac{R_{\\mathrm{u}}}{M_{\\mathrm{m}}}\n\\]\nwhere \\(R_{\\mathrm{u}}\\) is the universal gas constant. Then the molar fraction of each component is:\n\\[\ny_i = x_i \\frac{M_{\\mathrm{m}}}{M_i}\n\\]\nWith this composition, how do we sum up individual properties? Since what we have is temperature and pressure, we can use Amagat’s rule and add the volumes - but, since we are dealing with non-ideal gases, we should use a non-dimensional volume in the form of the compressibility factor:\n\\[\nZ = \\frac{P \\mathcal{V}}{m R T}\n\\]\nThe mixture rule is then\n\\[\nZ_{\\mathrm{m}} = \\sum_{i=1}^n y_i Z_i\n\\]\nwhere, since it’s an ideal gas, \\(Z_{\\mathrm{He}} = 1\\), and \\(Z_{\\mathrm{O_2}}\\) can be calculated from its equation of state. Here, we can use the mixture values of pressure and temperature, instead of partial values, as a way of already accounting for interaction forces and making the model more realistic [1].\nAt the initial state (1), then, this will give the initial mixture volume - which is preserved during the heating process. Now, if we calculate the new (at final state 2) compressibility factor of oxygen with the mixture volume instead of the pressure, there will probably a larger error, but we’’ll use that anyway\nI’ll use Python and the CoolProp library for calculating the fluid properties\nfrom CoolProp.CoolProp import PropsSI\nfrom scipy.constants import R as Ru\nimport numpy as np\n\n# convention: index 0 is helium, index 1 is oxygen\n\ncomponents = ['He','O2']\nmolar_masses = np.array([PropsSI('MOLARMASS',c) for c in components])\n\nx = np.array([1/3,2/3])\nm = 12\n\nMm = 1 / np.sum(x/molar_masses)\n\nRm = Ru/Mm\n\ny = x/molar_masses * Mm\n\nT1 = 170\nP1 = 7e6\n\nZ1 = np.array([1,PropsSI(\"Z\",\"T\",T1,\"P\",P1,components[1])])\nZm1 = np.dot(y,Z1)\n\nVm = Zm1 * m*Rm * T1/P1\n\nT2 = 220\n\n\n# notice that CoolProp work with density, not specific volumes\n# and we always use the mixture properties for the individual components\n# and only then apply mixture rule\ndensity = m/Vm\n\nZ2 = np.array([1,PropsSI(\"Z\",\"T\",T2,\"D\",density,components[1])])\nZm = np.dot(y,Z2)\n\nP2 = Zm * m*Rm * T2/Vm\n\nprint(\"New pressure = %.2f MPa\" %(P2*1e-6,))\n\nNew pressure = 9.90 MPa\nNow, to calculate heat transfer, we need to apply the First Law of Thermodynamics. Since we have a closed system with no volume variation and overall no indication of shaft work, the First Law reads:\n\\[\nQ = U_2 - U_1\n\\]\nwhere \\(U\\) is the total internal energy. Assuming there is no chemical reactions, the internal energy can be broken down into two separate systems, for each component. For helium (an ideal gas), we assume constant specific heats and use the fact that the internal energy of ideal gases depend only on temperatures. For the non-ideal oxygen gas, we use the residual enthalpy \\(\\Delta h^*\\), which is how much the enthalpy of the gas deviated from an ideal gas model. Keep in mind that:\n\\[\nu = h - Pv = h - ZRT\n\\]\nHence, to calculate the internal energy variation for oxygen, we need to account for three terms:\nCalculating everything:\nTmean = (T1 + T2)/2\n\n# notice that CoolProp does not have an ideal gas constant-volume specific heat\n# and that we have to provide a second argument, even if it only requires temperature\nR_He = Ru / molar_masses[0]\ncvHe = PropsSI(\"Cp0mass\",\"T\",Tmean,\"P\",P2,components[0]) - R_He\n\ndu_He = cvHe*(T2 - T1)\n\n# now, to use the residual properties, we have to use molar properties\n\ncpmolarO2 = PropsSI(\"Cp0molar\",\"T\",Tmean,\"P\",P2,components[1])\ndh_ig_O2 = cpmolarO2*(T2-T1)\n\ndresidual_1 = PropsSI(\"HMOLAR_RESIDUAL\",\"T\",T1,\"P\",P1,components[1])\ndresidual_2 = PropsSI(\"HMOLAR_RESIDUAL\",\"T\",T2,\"P\",P2,components[1])\ndhu = Ru*(Z2[1]*T2 - Z1[1]*T1)\n\ndu_O2 = 1/(molar_masses[1]) * (dh_ig_O2 + dresidual_2 - dresidual_1 - dhu)\n\nQ = m*(x[0]*du_He + x[1]*du_O2)\nprint(\"Heat transfer = %.2f kJ\" %(Q*1e-3))\n\nHeat transfer = 972.99 kJ"
  },
  {
    "objectID": "post/real/index.html#references",
    "href": "post/real/index.html#references",
    "title": "First Law Analysis of a Mixture of Non-Ideal Gases - Exercise 13-99 from Çengel’s Thermodynamics book (7th ed)",
    "section": "References",
    "text": "References\n[1]: Çengel, Y. A., & Boles, M. A. Termodinâmica (7 ed.). Porto Alegre: AMGH, 2013."
  },
  {
    "objectID": "post/color/index.html",
    "href": "post/color/index.html",
    "title": "Why and how to use different colors in VS Code for different projects",
    "section": "",
    "text": "I know what you are going to say: I’m weird, and apparently it makes no sense to spend time on things like this. But here it is: a post about setting different color schemes for VS Code, depending on which folder is open."
  },
  {
    "objectID": "post/color/index.html#why-setting-different-colors-is-good-for-productivity",
    "href": "post/color/index.html#why-setting-different-colors-is-good-for-productivity",
    "title": "Why and how to use different colors in VS Code for different projects",
    "section": "Why setting different colors is good for productivity",
    "text": "Why setting different colors is good for productivity\nFirst, let us say right away: if you spend some any significant time in a program, making it look more pleasant, so that you’ll want to spend more time with it, is super productive. Plus, hacking things is fun, and fun is always a good way to spend time.\nBut there is also a contextual component. CGP Grey illustrates how it is good to compartimentalize your life, to train your brain to associate certain environments with a desire to focus on certain things:\n\nIn this case, when I see a particular color scheme, I will immediately start to think about the project associated with those colors. Also, as I work with different projects alternating them within a given day (sometimes using different programming languages), assigning a different color scheme to each project help me differentiate between them."
  },
  {
    "objectID": "post/color/index.html#how-to-set-and-sync-color-schemes-in-vs-code",
    "href": "post/color/index.html#how-to-set-and-sync-color-schemes-in-vs-code",
    "title": "Why and how to use different colors in VS Code for different projects",
    "section": "How to set and sync color schemes in VS Code",
    "text": "How to set and sync color schemes in VS Code\nWhen you configure the editor’s settings, VS Code saves a JSON file with your customizations in a default location (see the aforelinked docs page). One of the settings is the color scheme. For my default color scheme, I like the Solarized Light theme:\n\n\n\nScreenshot of VS Code in the Solarized Light color scheme\n\n\nNow, how can this setting be changed based on the folder you open? It turns out you can open a particular folder in VS Code, which it calls a workspace (workspaces can actually combine different folders). In the Settings UI, you can set it to customize the workspace settings:\n\n\n\nScreenshot of the VS Code settings editor\n\n\nNow, when you save the settings, a settings.json file is created inside the folder you are in; in the figure below, I’ve setup the “local” color theme to a dark version of the solarized scheme - but this gets loaded only when I open up that particular folder!\n\n\n\nScreenshot of VS Code in the Solarized Dark color scheme"
  },
  {
    "objectID": "post/color/index.html#my-color-schemes",
    "href": "post/color/index.html#my-color-schemes",
    "title": "Why and how to use different colors in VS Code for different projects",
    "section": "My color schemes",
    "text": "My color schemes\nI’ll illustrate with two more projects to get you inspired. When I want to mess around with my dotfiles, I use a grey-ish, very utilitarian-looking color scheme (Atom Dark One):\n\n\n\nScreenshot of VS Code in a gray-like color scheme\n\n\nBut when I work in a project involving the Julia language, which is particularly associated with blue-purple colors (check their website), I configured VS Code with the “Tomorrow Night Blue” theme:\n\n\n\nScreenshot of VS Code in a blue-purple color scheme\n\n\nThis is very productive: I can have multiple VS Code windows (working in Julia while tweaking my dotfiles), and when I Alt-TAB the different colors are immediately apparent.\nPlease do tell me if I’m wasting my time…"
  },
  {
    "objectID": "post/monkey/index.html",
    "href": "post/monkey/index.html",
    "title": "Why I’m studying how to write an interpreter in Go… when I’m a Python developer",
    "section": "",
    "text": "I think there is no better way to start this blog about being obsessed with programming: an explanation (mostly for myself) on why I’m studying interpreters (when I do not develop anything related to that) implemented in Go (a language I do not use professionally)."
  },
  {
    "objectID": "post/monkey/index.html#why-this-subject",
    "href": "post/monkey/index.html#why-this-subject",
    "title": "Why I’m studying how to write an interpreter in Go… when I’m a Python developer",
    "section": "Why this subject?",
    "text": "Why this subject?\nThe first time I realized that studying interpreters and compilers is somethink I’d like to do was when re-reading The Pragmatic Programmer last year. I first read this book almost 10 years ago, when I was graduating college and started working more and more with programming, first in my internship and then in my Master’s studies. I remember it “being OK”, without much resonance; however, now that I’m primarily a software developer, I thought it was time for a review.\nThe Pragmatic Programmer starts with a list of tips that are obvious to me: be professional, care about your work, focus on quality, make learning a habit. The first tip that actually sounded as something new and noteworthy (at least for me, someone who doesn’t have a degree in Computer Science or anything related) was the importance of developing your own domain specific languages (DSL): think about common and repetitive tasks you have to do, encode how you would describe them in a dedicated language, and then create a program that will evaluate this language.\nAs it turns out, I do have lots of tasks that could use a specific language. In my daily work, I deal with JSON files that follow a specific configuration (describing inputs and outputs to simulations) that very often trigger the same sort of analysis. A DSL for my line of work would look like this:\nfor results in list_of_results:\n    plot temperature vs position\n    plot pressure vs position\n    calculate maximum pressure\n\nplot maximum pressure of each result vs initial pressure of each result\nThis actually would be useful! In addition, those very JSON files need to be parsed and validated - they also need to be interpreted in a way."
  },
  {
    "objectID": "post/monkey/index.html#the-book",
    "href": "post/monkey/index.html#the-book",
    "title": "Why I’m studying how to write an interpreter in Go… when I’m a Python developer",
    "section": "The book",
    "text": "The book\nIn the beginning of this year, then, I decided to give Writing an Interpreter in Go a try, inspired by this video (which made me also learn OCaml just because, but that’s a story for another time).\nhttps://www.youtube.com/watch?v=NjKJ9-ejR6o\nI’m still on the second chapter, but I’m loving it. The book is well written, didactic without assuming the reader is stupid. It doesn’t require the reader know a lot of Go, and it doesn’t waste time explaning the syntax either - I can always just look it up.\nThis is a book for software developers, and the author assumes software developer can learn details of programming languages. Most importantly, it’s a book about software development: thinking about data structures, developing incremental tests for their behaviour, not being afraid of creating functions that have just one line of code if they make understanding the program much easier, organizing the code into separate modules. All of these are useful things that I always to improve in my job."
  },
  {
    "objectID": "post/monkey/index.html#what-im-applying-in-my-daily-work-as-a-python-developer",
    "href": "post/monkey/index.html#what-im-applying-in-my-daily-work-as-a-python-developer",
    "title": "Why I’m studying how to write an interpreter in Go… when I’m a Python developer",
    "section": "What I’m applying in my daily work as a Python developer",
    "text": "What I’m applying in my daily work as a Python developer\nMy main project at work is a simulator that was originally written by another very talented engineer, and that I now have to maintain and extend. Very often we and our clients deal with problems when reading and parsing the input files: some fields are missing or they are too complex. Inspired by these studies, I’m becoming less and less afraid of creating small data structures and functions that process one small part at a time - instead of just trying to conform to what is already in the code.\nYes, I develop Python application, but the language is just a detail. The book could be re-written in Python and the ideas, the theory, the methods would be the same. If I re-implemented my main project in Go (which I actually dream of, to get all the static cross-compilation benefits), my clients couldn’t care less - they want simulation results. I’m a firmly believer of being programming languages polyglot and being able to study books that show code in different languages.\nI’ll have more to say when I advance in the book and use more and more of its ideas in my Python projects. In the meanwhile, give Writing an Interpreter in Go… a go."
  },
  {
    "objectID": "post/go/index.html",
    "href": "post/go/index.html",
    "title": "Studying Go to get better at Python: reader and writer interfaces",
    "section": "",
    "text": "In my day job, I mainly write Python code, but I dedicate a good amount of time to studying the Go programming language. Here’s one good example that shows why it’s so useful."
  },
  {
    "objectID": "post/go/index.html#the-importance-of-thinking-about-io",
    "href": "post/go/index.html#the-importance-of-thinking-about-io",
    "title": "Studying Go to get better at Python: reader and writer interfaces",
    "section": "The importance of thinking about IO",
    "text": "The importance of thinking about IO\nThe kind of programs I write are command line applications that take some specification file in and produce an output file with simulation results; both input and output files are JSON files. I develop these programs for our clients, but I also use them for our own analysis and research. That means that I’m always writing more and more scripts and that analyze the input and output data our main software consumes. The question: how can I add flexibility to this? How can I choose to save the output JSON object to a file, or to the terminal for some quick checking, or to some in-memory object for testing?\nI’ve never seen this type of discussion in Python literature - in fact, before studying Go books, I rarely though of that problem, and had my programs always read from and write to disk files. This is simple, but make testing more cumbersone (I have to always create and delete temporary files) and inefficient."
  },
  {
    "objectID": "post/go/index.html#studying-go-reader-and-writer-interfaces",
    "href": "post/go/index.html#studying-go-reader-and-writer-interfaces",
    "title": "Studying Go to get better at Python: reader and writer interfaces",
    "section": "Studying Go: reader and writer interfaces",
    "text": "Studying Go: reader and writer interfaces\nBut Go books are full of examples that use Reader and Writer interfaces. Here’s some sample (and incomplete) code from one of the example programs of the excelent Powerful Command Line Applications with Go: a function that takes a filename, open that filename for processing, saves the processed data to a temporary file, and writes the path of that file to a Writer interface out:\n//main.go\n\nfunc run(filename string, out io.Writer) error {\n  // Read all the data from the input file and check for errors \n  input, err := ioutil.ReadFile(filename)\n  if err != nil {\n    return err \n  }\n  \n  // create a temporary file to store processed data\n  temp, err := ioutil.TempFile(\"\", \"mdp*.html\") \n  if err != nil {\n    return err \n  }\n  \n  // do some processing with input and save to temp\n  // ...\n  \n  // close the file\n  if err := temp.Close(); err != nil { \n    return err\n  }\n  \n  // save the results filename to this out interface for checking\n  // e.g. checking that it contains the right data\n  outName := temp.Name()\n  fmt.Fprintln(out, outName)\n  \n  // ... return some status\n}\n  \nThe details are not important, which is why I skipped many lines. What’s important is this: in a test file, I can create a buffer in which to write the filename:\n//main_test.go\n\nfunc TestRun(t *testing.T) { \n  var mockStdOut bytes.Buffer\n  if err := run(inputFile, &mockStdOut); err != nil { \n  t.Fatal(err)\n  }\n  \n  // mockStdOut contains the resultsfilename, \n  // which we then store in avariable\n  resultFile := strings.TrimSpace(mockStdOut.String())\n  \n  // and now read that file\n  result, err := ioutil.ReadFile(resultFile)\n  \n  // do some checks with results\n  }\nAnd, in the actual application, I can just use the system stdout:\n// main.go\n\n// definition of the function run(...) as above\n\nfunc main() {\n  // Parse flags\n  filename := flag.String(\"file\", \"\", \"File to process\") \n  flag.Parse()\n  // If user did not provide input file, show usage\n  if *filename == \"\" { flag.Usage() os.Exit(1)\n  }\n  if err := run(*filename, os.Stdout); err != nil { \n    fmt.Fprintln(os.Stderr, err)\n    os.Exit(1)\n  } \n}\nDid you see what happened? The same function can be passed an internal buffer for testing (no writing files required), or the actual terminal in the final application."
  },
  {
    "objectID": "post/go/index.html#parametrizing-io-in-python",
    "href": "post/go/index.html#parametrizing-io-in-python",
    "title": "Studying Go to get better at Python: reader and writer interfaces",
    "section": "Parametrizing IO in Python",
    "text": "Parametrizing IO in Python\nHow can I reproduce this technique in Python? Here is some sample module that is similar to the example above:\n\"\"\"main.py - the best simulator ever written.\"\"\"\n\nfrom typing import TextIO\nimport sys\n\ndef run(out: TextIO) -&gt; None:\n    out.write(\"I just did some awesome simulation!\\n\")\n\nif __name__ == \"__main__\":\n    run(sys.stdout)\nIf you run, you get the expected result:\npython main.py\n# I just did some awesome simulation!\nBut for testing, we can use a StringIO object, which acts like the buffer we saw earlier:\n\"\"\"test_main.py - Check that we are indeed awesome\"\"\"\n\nimport main\nimport io\n\ndef test_main():\n    mock = io.StringIO()\n\n    main.run(mock)\n\n    message = mock.getvalue()\n\n    assert message == \"I just did some awesome simulation!\\n\"\nWhen running this case with pytest (pytest test_main.py, provided why files are in the same directory), the test passes. We did not have to read from stdout, nor save anything to a file, both of which require more code to be written."
  },
  {
    "objectID": "post/go/index.html#studying-go-is-not-a-waste-of-time-even-if-you-do-not-write-go",
    "href": "post/go/index.html#studying-go-is-not-a-waste-of-time-even-if-you-do-not-write-go",
    "title": "Studying Go to get better at Python: reader and writer interfaces",
    "section": "Studying Go is not a waste of time even if you do not write Go",
    "text": "Studying Go is not a waste of time even if you do not write Go\nWhat does this mean in practice? It means you stop writing print() statements all over the place, and think about what is being read and written. This forces me to think of the software at a higher level.\nI think there’s a gap in Python literature: too much focus on new syntax constructions (which are very nice), too focus on Jupyter notebooks, and too little focus in software development: testing, structuring code, making it easier to extend. Both Writing Powerful Command-Line Applications in Go and Writing Interpreters in Go focus on that: writing useful programs, without nitty-picking syntax details.\nWhy my obsession with Go in particular? It’s just that the literature is full of good books, and it’s a modern language with a clean syntax, powerful and easy to learn in incremental steps. Slowly but surely, I’m beginning to write more and more Go programs almost as more powerful shell scripts, because it’s so pleasant to do that. I highly recommend addying this language to your repertoire."
  },
  {
    "objectID": "post/superheat/index.html",
    "href": "post/superheat/index.html",
    "title": "Including superheat in the compressor regression",
    "section": "",
    "text": "We are always learning. After studying more about compressor datasheets, I realized that I forgot to include the superheat in yesterday’s post. Let’s fix that.\nThe main problem is that, in every calculation, I took the inlet state as saturated vapor in the given evaporating temperature, when in reality the datasheet specifies that the vapor always enters at 32.2 ºC.\nSo let’s start again. We will read the dataset with pandas:\nimport pandas as pd\n\ndf = pd.read_csv(\"compressor.csv\",delimiter=',')\nprint(df)\n\n   Evaporating Temperature [C]  Condensing temperature [C]  \\\n0                          -35                          35   \n1                          -30                          35   \n2                          -25                          35   \n3                          -20                          35   \n4                          -15                          35   \n5                          -10                          35   \n\n   Cooling Capacity [W]  Power [W]  Current [A]  Gas Flow Rate [kg/h]  \\\n0                   167        129         1.21                  1.79   \n1                   218        144         1.23                  2.34   \n2                   282        160         1.27                  3.03   \n3                   362        177         1.32                  3.89   \n4                   457        197         1.38                  4.93   \n5                   570        217         1.45                  6.16   \n\n    Efficiency [W/W]  \n0               1.29  \n1               1.52  \n2               1.77  \n3               2.04  \n4               2.33  \n5               2.63\nThe sections below are mostly a repetition, but we’ll update the equations where necessary:"
  },
  {
    "objectID": "post/superheat/index.html#how-to-calculate-the-mass-flow-rate-of-a-compressor",
    "href": "post/superheat/index.html#how-to-calculate-the-mass-flow-rate-of-a-compressor",
    "title": "Including superheat in the compressor regression",
    "section": "How to calculate the mass flow rate of a compressor?",
    "text": "How to calculate the mass flow rate of a compressor?\nA reciprocating compressor like this one is a volumetric machine: it displaces a certain volume of fluid, based on its internal geometry, and the mass flow rate depends on the suction state.\nThe most basic, ideal model is then:\n\\[\n\\dot{m} = \\frac{\\dot{\\mathcal{V}} _{\\mathrm{D}}}{v _{\\mathrm{in}}}\n\\]\nwhere the numerator is the displacement rate; for a compressor with \\(z\\) cylinders at a fixed rotation speed \\(n\\) it can be calculated\n\\[\n\\dot{\\mathcal{V}} _{\\mathrm{D}} = {\\mathcal{V}} _{\\mathrm{D}} n z\n\\]\nwhere \\(\\mathcal{V} _{\\mathrm{D}}\\) is the internal displacement.\nLet’s plot the actual mass flow rate from the datasheet (using the geometric parameters from it) and the above model to compare:\n\nimport matplotlib.pyplot as plt\nfrom CoolProp.CoolProp import PropsSI\nimport numpy as np\n\nplt.rc('font', size=12)\n\nVd = 13.54e-6 # in m3\nn = 60 #Hz\nz = 1\nfluid = 'R600a'\nTreturn = 32.2 + 273\n\nVd_dot = Vd * n * z # m3/s\nT_evap = df[\"Evaporating Temperature [C]\"].values\nm_dot_actual = df[\"Gas Flow Rate [kg/h]\"].values\n\n# we take the inverse of the density \n# of the vapor at the evaporing *pressure*\n# and the return gas temperature\nv_in = np.array([(1.0/PropsSI(\"D\",\"T\",Treturn,\"P\",PropsSI(\"P\",\"T\",Te+273,\"Q\",1,fluid),fluid)) for Te in T_evap])\nm_dot_ideal = 3600*Vd_dot/v_in\n\nfig, ax = plt.subplots()\nax.plot(T_evap,m_dot_ideal,'k-',label=\"Ideal\")\nax.plot(T_evap,m_dot_actual,'ko',label=\"Actual\")\nax.set_xlabel(\"Evaporating temperature [ºC]\")\nax.set_ylabel(\"Gas flow rate [kg/h]\")\nax.legend()\nax.grid()\nplt.show()\n\n\n\n\n\n\n\n\nClearly our model is not good enough! There is a volumetric efficiency that is influenced by dead volumes and leakages:\n\\[\n\\eta_{\\mathrm{v}} = \\frac{\\dot{m}}{\\frac{\\dot{\\mathcal{V}} _{\\mathrm{D}}}{v _{\\mathrm{in}}}}\n\\]\n\neta_v = m_dot_actual/m_dot_ideal*100\nfig2, ax2 = plt.subplots()\n\nax2.plot(T_evap,m_dot_actual,'ko-',label=\"Actual mass flow rate\")\nax2.set_xlabel(\"Evaporating temperature [ºC]\")\nax2.set_ylabel(\"Gas flow rate [kg/h] (dots)\")\n\nax3 = ax2.twinx()\nax3.plot(T_evap,eta_v,'kx--',label=\"Volumetric efficiency\")\nax3.set_ylabel(\"Volumetric efficiency [%] (x)\")\nax2.grid()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nWhat influences the volumetric efficiency?\nThe volumetric efficiency depends primarily on the pressure ratio between condensing and evaporating levels:\n\\[\nr _{\\mathrm{p}} = \\frac{P _{\\mathrm{cond}}}{P _{\\mathrm{evap}}}\n\\]\nSo let’s plot that:\n\neta_v = m_dot_actual/m_dot_ideal\n\nPcond = PropsSI(\"P\",\"T\",df[\"Condensing temperature [C]\"].values[0]+273,\"Q\",1,fluid)\nPevap = np.array([PropsSI(\"P\",\"T\",Te+273,\"Q\",1,fluid) for Te in T_evap])\nrp = Pcond/Pevap\nfig20, ax20 = plt.subplots()\n\n\n\nax20.plot(rp,eta_v,'ko-')\nax20.set_xlabel(\"Pressure ratio\")\nax20.set_ylabel(\"Volumetric efficiency\")\n\nplt.show()\n\n\n\n\n\n\n\n\nMaybe we can use a log-log plot?\n\neta_v = m_dot_actual/m_dot_ideal\n\nPcond = PropsSI(\"P\",\"T\",df[\"Condensing temperature [C]\"].values[0]+273,\"Q\",1,fluid)\nPevap = np.array([PropsSI(\"P\",\"T\",Te+273,\"Q\",1,fluid) for Te in T_evap])\nrp = Pcond/Pevap\nfig20, ax20 = plt.subplots()\n\n\n\nax20.plot(rp,eta_v,'ko-')\nax20.set_xlabel(\"Pressure ratio\")\nax20.set_ylabel(\"Volumetric efficiency\")\nax20.set_yscale('log')\nax20.set_xscale('log')\n\nplt.show()\n\n\n\n\n\n\n\n\nwhich seems to make the relationship linear. A candidate for a model would be then:\n\\[\n\\ln \\eta_{\\mathrm{v}} = b_0 + b_1 \\ln r_{\\mathrm{p}}\n\\]\nAs with yesterday’s post, We will use scikit-learn to train a model to calculate the coefficients, based on 50% of the data selected at random:\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nX = np.log(rp).reshape(-1,1)\nY = np.log(eta_v)\n\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.5)\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X_train, Y_train)\n\nfig4, ax4 = plt.subplots()\nax4.plot(np.log(rp),np.log(eta_v),'ko')\nax4.plot(X,model.predict(X),'k-')\nax4.set_xlabel(\"Log of Pressure ratio\")\nax4.set_ylabel(\"Log of Volumetric efficiency\")\nax4.set_title('accuracy (R^2) =  %.5f'\n% r2_score(Y_test, model.predict(X_test)))\nplt.show()\n\n\n\n\n\n\n\n\nThe advantage of using the pressure ratio as the main feature is that the effect of the superheat degree is probably low, but we need more data with the same pressure ratio and different degrees of superheat to be sure."
  },
  {
    "objectID": "post/superheat/index.html#polynomials-for-cooling-capacity",
    "href": "post/superheat/index.html#polynomials-for-cooling-capacity",
    "title": "Including superheat in the compressor regression",
    "section": "Polynomials for cooling capacity",
    "text": "Polynomials for cooling capacity\nThe other useful thing to do with a compressor datasheet of calculating a polynomial of the form [1]:\n\\[\n\\dot{Q} _{\\mathrm{L}} = a _0 + a _1  t _{\\mathrm{evap}} + a _2  t _{\\mathrm{evap}}^2\n\\]\nwhere \\(\\dot{Q}_{\\mathrm{L}}\\) is the cooling capacity and \\(t_{\\mathrm{evap}}\\) is the evaporating temperature in degress Celsius. Four points of note:\n\nThis polynomial allows you to interpolate in different points other than the tabulated ones, an also can be combined with other models in the refrigeration system;\nThe coefficients themselves are function of the condensing temperature, the fluid properties and the compressor geometry;\nThe same thing can be done for the power consumption, with different coefficients;\nThe resulting polynomial is valid for the same compressor in different evaporating pressures, but keeping the superheat and subcooling degress the same as the values from the datasheet.\n\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\n\nX = df.values[:,:1] # first column (evaporating temperature) as a 2D array, as required\nYQL = df[\"Cooling Capacity [W]\"].values\n\nX_train,X_test,QL_train,QL_test = train_test_split(X,YQL,test_size=0.5)\n\nQL_quadratic_model = Pipeline(\n[\n('poly', PolynomialFeatures(degree=2)),\n('linear', LinearRegression(fit_intercept=False))])\nQL_quadratic_model.fit(X_train, QL_train)\nQL_quadratic_pred = QL_quadratic_model.predict(X_test)\n\nfig4, ax4 = plt.subplots()\nax4.scatter(QL_test,QL_quadratic_pred)\nax4.grid()\nax4.set_xlabel('Simulated cooling capacity [W]]')\nax4.set_ylabel('Predicted cooling capacity [W]')\nax4.set_title('accuracy (R^2) =  %.5f'\n% r2_score(QL_test, QL_quadratic_pred))\nplt.show()\n\n\n\n\n\n\n\n\nThe resulting coefficients are (from \\(a_0\\) to \\(a_2\\)):\n\nprint(QL_quadratic_model.named_steps[\"linear\"].coef_)\n\n[8.47e+02 3.11e+01 3.40e-01]\n\n\nHence, this polynomial seems to work fine, even though we have very few data points; with more data points in a test apparatus, this same model could be retrained, making the coefficients more and more accurate.\nThe advantage of this approach is that, if we are working with this compressor and selecting heat exchangers sizes, for instance, we do not need to evaluate thermophysical properties at each iteration but only a polynomial, which is a huge time saver. How to make this integration between models is the subject of another post."
  },
  {
    "objectID": "post/superheat/index.html#references",
    "href": "post/superheat/index.html#references",
    "title": "Including superheat in the compressor regression",
    "section": "References",
    "text": "References\n[1]: Stoecker, W. F. Design of thermal systems. [sl]: McGraw-Hill, 1980."
  },
  {
    "objectID": "post/julia/index.html",
    "href": "post/julia/index.html",
    "title": "I’m a Python developer - and this is why I’m learning Julia",
    "section": "",
    "text": "There’s no surprise that I’m big on Python, but there is something that I can’t get out of my mind:\nHere’s a philosophical question: should I focus on getting better and better at Python development, or should I actually devote time to learn other languages such as Julia, R and maybe others? Which path will make me better at my job?"
  },
  {
    "objectID": "post/julia/index.html#should-engineers-should-be-programming-languages-polyglots",
    "href": "post/julia/index.html#should-engineers-should-be-programming-languages-polyglots",
    "title": "I’m a Python developer - and this is why I’m learning Julia",
    "section": "Should engineers should be (programming languages) polyglots?",
    "text": "Should engineers should be (programming languages) polyglots?\nMy wife jokes that I talk too much about two heroes of mine: Cal Newport and Austin Kleon. In fact, my own style of working is an intersection of the two, which seem conflicting at first. The Newport approach should tell me to have “laser focus” on one skill, to be So Good They Can’t Ignore Me and become the best Python developer/Mechanical Engineer in the planet. The Kleon approach would be to Steal Like an Artist from all my influences and build my own work from them.\nI do think it’s possible to combine these two modes of working. I am not as focused as Cal Newport and cannot drop projects and ideas serially as he claims to do – my brain simply refuses to do it. I like to explore ideas, and techniques, and programming languages too much to do that. However — while I’m exploring, I can indeed focus and dive deep into what I’m learning, and not just try to be superficial.\nSo yes, I think developers and engineers should build their programming languages toolbox, and avoid the “I can only do that in Python” mentality. You can’t learn every programming language in the world, but having a few in your pocket might help you solve problems (you are an engineer, right?) in a quasi-optimal way.\nThis way, you focus on getting increasingly better as a developer in general, and not as a Python developer:\n\nMy main point is this: the more languages you learn, the more you learn about programming in general."
  },
  {
    "objectID": "post/julia/index.html#what-julia-can-teach-a-python-developer",
    "href": "post/julia/index.html#what-julia-can-teach-a-python-developer",
    "title": "I’m a Python developer - and this is why I’m learning Julia",
    "section": "What Julia can teach a Python developer",
    "text": "What Julia can teach a Python developer\nJulia is built to be fast:\n\nIn my experience, as someone who is not a computer scientist by training, and who work with people with a similar background but who still code all day, engineers tend to “hack” a Python script to do some sort of simulation or data processing, realize it takes forever to run, and then do nothing about it.\nQuite frankly, I’m learning Julia because my co-workers work in Julia and I don’t want to be a bottleneck, everytime having to translate everything into Python back and forth. And in my initial explorations, I’m finding that the Julia language emphasizes vectorization, and making the code as generic as possible. Plus it is a semi-return to compiled languages (I actually learned to program in C, which sounds absurd today).\nJulia also has some interesting new packages, being the “new kid in the block”: I love the workflow emphasized by DrWatson (this alone almost is a reason to try out Julia in the first place) and the “evolution of notebooks” prescribed by Pluto.\nI know in the Instagram post above I referenced also the R language - we’ll leave that to another post."
  },
  {
    "objectID": "post/julia/index.html#you-want-to-try-out-julia-too",
    "href": "post/julia/index.html#you-want-to-try-out-julia-too",
    "title": "I’m a Python developer - and this is why I’m learning Julia",
    "section": "You want to try out Julia too?",
    "text": "You want to try out Julia too?\nFor a deep 4-hours long session on the “scientific computing” approach to coding in Julia, this video by George Datseris (one of the developers of DrWatson) is excelent.\nFor the specifics of working with Julia (tools, installing, main libraries), I recommend the free online book Julia Data Science.\nLet’s discuss in the comments below what do you think Julia and Python (and R etc.)!"
  },
  {
    "objectID": "post/whats/index.html",
    "href": "post/whats/index.html",
    "title": "What is this site",
    "section": "",
    "text": "Hi there. I’m Fábio Fortkamp, a Professor of Mechanical Engineering from Brazil. This is my academic website, where I post explorations in Thermal Engineering, R, Python, and Mechanical Engineering in general.\nThis site is my attempt to more properly show my work. As I study, prepare for lectures, and develop my research, I will try to post my discoveries here. In particular, at least in this stage, I will focus on solving problems on Thermodynamics, Heat Transfer, Heat Engines, Refrigeration Systems using computational tools. Python and R are the main tools I use; my mission is to make the next generation of Engineers more apt to solve real-life problems with data science and programming concepts. More exploration, and less memorization.\nThanks in advance for reading."
  },
  {
    "objectID": "post/first/index.html",
    "href": "post/first/index.html",
    "title": "First Law Analysis of a Mixture of Ideal Gases - Exercise 13-97 from Çengel’s Thermodynamics book (7th ed)",
    "section": "",
    "text": "This is exercise 13-97 from [1]: a mixture of gases composed of 55% of nitrogen gas and 45% of carbon dioxide (in mass) is originally at 200 kPa and 45 ˚C. The system is heated up and expands, but due to the action of a spring, the pressure variation as a function of volume \\(P(\\mathcal{V})\\) follows:\n\\[\nP = A + K \\mathcal{V}\n\\] where \\(A = 111.111\\,\\mathrm{kPa}\\) and \\(K = 888.89\\,\\mathrm{kPa/m^3}\\). During the heating, volume doubles; what is the work and heat transfers associated with the process?\nFor that, in contrast with the previous posts, now we’ll use Python and the pyromat package, which I’ve just discovered today.\nWith the added heat, the system will expand and perform work, which can be calculated using only mechanics:\n\\[\nW = \\int_{\\mathcal{V}_1}^{\\mathcal{V}_2} P \\mathrm{d}\\mathcal{V}\n\\]\nWhere the initial volume can be obtained from the given pressure variation, and the final volume is double that:\nA = 111.111\nK = 888.89\n\nP1 = 200\nV1 = (P1-A)/K\nprint(\"V1 = %.2f m3\" %(V1))\nV2 = 2*V1\n\nV1 = 0.10 m3\nThe integration above gives:\n\\[\nW = A * (\\mathcal{V}_2 - \\mathcal{V}_1) + \\frac{K}{2}\\left(\\mathcal{V}_2^2 - \\mathcal{V}_1^2\\right)\n\\]\nand calculating it:\nW = A*(V2-V1) + K/2*(V2**2 - V1**2)\nprint(\"W = %.2f kJ\" %(W,))\n\nW = 24.44 kJ\nTo compute the heat added to the system, a First Law analysis reads:\n\\[\nQ = W + \\Delta U = W + m c_v (T_2-T_1)\n\\]\nwhere, assuming a mixture of ideal gases (an hypothesis not used so far!), all mass-specific properties are additive. The gas constant is:\n\\[\nR = \\sum_{i=1}^k x_i R_i\n\\] where \\(k = 2\\) components, \\(x_i\\) is the individual mass fraction and \\(R_i\\) the individual gas constant. The gas constant is needed to compute the temperature variation; at state 1, the mass (which is constant in all states for a closed system) is computed from the ideal gas equation of state:\n\\[\nm = \\frac{P_1 V_1}{R T_1}\n\\]\nand now, applying the same equation for state 2:\n\\[\nT_2 = \\frac{P_2 V_2}{m R}\n\\]\nwhere \\(P_2\\) can be obtained from the pressure-volume equation.\nThe constant-volume specific heat for ideal gases is a function of temperature only, and for better accuracy can be calculated at the average temperature. The mixture specific heat is computed similarly to the gas constant above.\nThe pyromat library has function to create ideal gas “objects” and then access constants and functions as illustrated below:\nimport pyromat as pm\nN2 = pm.get(\"ig.N2\") # ig = ideal gas model\nCO2 = pm.get(\"ig.CO2\")\n\nxN2 = 0.55\nxCO2 = 1-xN2\n\n# each object has a .R() method to calculate the gas constant\n# the default units are kJ, kPa, m3, K, kmol\nR = xN2*N2.R() + xCO2*CO2.R()\n\nT1 = 45 + 273\nm = (P1*V1)/(R*T1)\n\nP2 = A + K*V2\nT2 = (P2*V2)/(m*R)\n\nTmean = (T1 + T2)/2\n\ncv = xN2*N2.cv(T=Tmean) + xCO2*CO2.cv(T=Tmean)\n\nQ = W + m*cv*(T2-T1)\nprint(\"Q = %.2f kJ\" %(Q,))"
  },
  {
    "objectID": "post/first/index.html#references",
    "href": "post/first/index.html#references",
    "title": "First Law Analysis of a Mixture of Ideal Gases - Exercise 13-97 from Çengel’s Thermodynamics book (7th ed)",
    "section": "References",
    "text": "References\n[1]: Çengel, Y. A., & Boles, M. A. Termodinâmica (7 ed.). Porto Alegre: AMGH, 2013."
  },
  {
    "objectID": "post/compressibility/index.html",
    "href": "post/compressibility/index.html",
    "title": "Compressibility and Expandability: what are they and how to calculate",
    "section": "",
    "text": "One of my disappointments back when I was teaching is that I never taught a Thermodynamics class. I heard it is a terrible subject to teach, with high failing rates, but I’d like to have that experience nevertheless.\nSpeaking as someone who studied Thermodynamics as an undergrad student and then during graduate school, and who taught classes that depended on Thermodynamics, I think there is a big specific problem with these courses: students have this subject too early in the curriculum, without the maturity to proper understand the difficult concepts. Also, it becomes too easy to forget what you saw in a Thermodynamics class 15 years ago."
  },
  {
    "objectID": "post/compressibility/index.html#expansion-coefficients",
    "href": "post/compressibility/index.html#expansion-coefficients",
    "title": "Compressibility and Expandability: what are they and how to calculate",
    "section": "Expansion coefficients",
    "text": "Expansion coefficients\nI’m telling this story from personal experience: I’m working on a project where I have to deal with two “expansion coefficients” that all substances have – how they expand (or contract) upon receiving energy – , but that do not appear often in most thermodynamic analyses. Hence, I had to go back to the textbooks to understand them.\nI’m taking the definitions below from [1]. The first coefficient is the volumetric isobaric expansivity, which measured how the volume of a substance changes you heat it up at constant pressure:\n\\[\n\\beta = \\frac{1}{v}\\left(\\frac{\\partial v}{\\partial T}\\right)_p\n\\]\nwhere \\(v\\) is the specific volume, \\(p\\) is the pressure and \\(T\\) the absolute temperature. This coefficient has units of K\\(^{-1}\\), and can be negative; famously, liquid water expands when cooled down below 4 ºC (this is why water bottles can break in the freezer). Most substances, however, expand when heated up (\\(\\beta &gt; 0\\)).\nThe volumetric expansivity may be familiar to Heat Transfer students, and it appears in Free Convection theory; fluids with large values of \\(\\beta\\) change density substantially and then move around quickly when temperature gradients are present.\nThe other coefficient is the isothermal compressibility:\n\\[\n\\alpha = -v \\left(\\frac{\\partial v}{\\partial p}\\right)_T\n\\]\nThis coefficient, with units of Pa\\(^{-1}\\) can never be negative: if you exert force in a piston with some fluid at constant temperature, it will contract."
  },
  {
    "objectID": "post/compressibility/index.html#calculating-expansivity-and-compressibility-with-coolprop",
    "href": "post/compressibility/index.html#calculating-expansivity-and-compressibility-with-coolprop",
    "title": "Compressibility and Expandability: what are they and how to calculate",
    "section": "Calculating expansivity and compressibility with CoolProp",
    "text": "Calculating expansivity and compressibility with CoolProp\nBeware that the coefficients above have many names, depending on the source you are using. To calculate them using the CoolProp library in Python, for instance, I had to look up the available functions.\nNotice that, as derivatives of \\(p-v-T\\) relations, \\(\\alpha\\) and \\(\\beta\\) are properties of state, depending on two other properties to be calculated. For instance, the expansivity of air at atmospheric pressure and ambient temperature is:\n\nfrom CoolProp.CoolProp import PropsSI\nT0 = 298 # K\nP0 = 101.325e3 # Pa\nfluid = 'Air'\nbeta = PropsSI(\"ISOBARIC_EXPANSION_COEFFICIENT\",\"T\",T0,\"P\",P0,fluid)\nprint(\"%.3e K^-1\" %(beta,))\n\n3.365e-03 K^-1\n\n\nAnd the compressibility can be calculated as:\n\nalpha = PropsSI(\"ISOTHERMAL_COMPRESSIBILITY\",\"T\",T0,\"P\",P0,fluid)\nprint(\"%.3e Pa^-1\" %(alpha,))\n\n9.872e-06 Pa^-1"
  },
  {
    "objectID": "post/compressibility/index.html#relationship-to-specific-heat",
    "href": "post/compressibility/index.html#relationship-to-specific-heat",
    "title": "Compressibility and Expandability: what are they and how to calculate",
    "section": "Relationship to specific heat",
    "text": "Relationship to specific heat\nThe Mayer relation is [1]:\n\\[\nc_p - c_v = \\frac{vT\\beta^2}{\\alpha}\n\\]\nwhere \\(c_p\\) and \\(c_v\\) are respectively the constant-pressure and constant-volume speficic heats. The right hand side is always non-negative, which enforces \\(c_p \\ge c_v\\). The equality sign applies from incompressible substances, for which \\(\\beta = 0\\).\nLet us verify that relation:\n\nc_p = PropsSI(\"CPMASS\",\"T\",T0,\"P\",P0,fluid)\nc_v = PropsSI(\"CVMASS\",\"T\",T0,\"P\",P0,fluid)\nv = 1/PropsSI(\"D\",\"T\",T0,\"P\",P0,fluid)\nprint(c_p - c_v - v*T0*beta**2/alpha)\n\n0.0\n\n\n\nAn aside about how these properties are calculated\nEngineers should beware of black boxes. In the examples above (and below), what exactly is CoolProp doing?\nIf you are doing a serious project involving thermodynamic and transport properties, you should definitely check out the CoolProp documentation on fluid properties\nAs explained before, \\(\\alpha\\) and \\(\\beta\\) can be calculated with only knowledge of the equation of state (EOS). Specific heats cannot be calculated from an EOS; additional information about the energy of the fluid is needed [2], usually from empirical correlations. What the Mayer relation enforces is that only the difference between specific heats can be determined from an EOS; but if you also have a model for \\(c_p\\), you can calculate \\(c_v\\) and vice-versa. You don’t need two different models for the two specific heats.\nCheck out the CoolProp documentation page above to see what other information, besides the EOS, is needed to build up the CoolProp database."
  },
  {
    "objectID": "post/compressibility/index.html#comparison-between-gases",
    "href": "post/compressibility/index.html#comparison-between-gases",
    "title": "Compressibility and Expandability: what are they and how to calculate",
    "section": "Comparison between gases",
    "text": "Comparison between gases\nIf we pick only gases commonly present in mechanical engineering applications, how do the values of \\(\\alpha\\) and \\(\\beta\\) vary between them?\nWhen doing this sort of analysis, I always find it useful to use pandas to build a table and work from there:\n\nfrom pandas import Series, DataFrame\nimport numpy as np\n\ngases = [\n  \"Air\",\n  \"Argon\",\n  \"CarbonDioxide\",\n  \"Ethane\",\n  \"Helium\",\n  \"IsoButane\",\n  \"Nitrogen\",\n  \"Methane\"]\n  \nalphav = np.empty_like(gases,dtype='float')\nbetav = np.empty_like(gases,dtype='float')\n\nfor i,gas in enumerate(gases):\n  alphav[i] = PropsSI(\"ISOTHERMAL_COMPRESSIBILITY\",\"T\",T0,\"P\",P0,gas)\n  betav[i] = PropsSI(\"ISOBARIC_EXPANSION_COEFFICIENT\",\"T\",T0,\"P\",P0,gas)\n\ndf = DataFrame(\n  {\n    \"Gas\": gases,\n    \"alpha [MPa^-1]\": 1e6*alphav,\n    \"beta [K-1]\": betav\n}\n)\nprint(df)\n\n             Gas  alpha [MPa^-1]  beta [K-1]\n0            Air        9.872466    0.003365\n1          Argon        9.875500    0.003366\n2  CarbonDioxide        9.919539    0.003412\n3         Ethane        9.945354    0.003435\n4         Helium        9.864455    0.003354\n5      IsoButane       10.145642    0.003660\n6       Nitrogen        9.871181    0.003364\n7        Methane        9.886582    0.003377\n\n\nFrankly, this result, with this low variation between gases, surprises me. Mind you that CoolProp is not just using Ideal Gas relations (otherwise the compressibility and expandability of the gases would be equal - prove it!), but is actually using experimental \\(p-v-T\\) data. It just so happens that there is not a wide variation between gases."
  },
  {
    "objectID": "post/compressibility/index.html#final-remarks",
    "href": "post/compressibility/index.html#final-remarks",
    "title": "Compressibility and Expandability: what are they and how to calculate",
    "section": "Final remarks",
    "text": "Final remarks\nI’ve written this post because I needed to learn more about these properties, and I hope it will help more people. Please share it if you find it useful!"
  },
  {
    "objectID": "post/compressibility/index.html#references",
    "href": "post/compressibility/index.html#references",
    "title": "Compressibility and Expandability: what are they and how to calculate",
    "section": "References",
    "text": "References\n[1]: Çengel, Y. A., & Boles, M. A. Termodinâmica (7 ed.). Porto Alegre: AMGH, 2013.\n[2]: Callen, H. B. Thermodynamics and an Introduction to Thermostatistics (2nd ed.). John Wiley and Sons, 1985."
  },
  {
    "objectID": "post/inspectional/index.html",
    "href": "post/inspectional/index.html",
    "title": "Stages of studying: 1 - Inspectional Reading",
    "section": "",
    "text": "Adler and Van Doren’s How to Read a Book is one of the my favorite books. Although the authors talk about “normal” books (fiction, non-fiction, poetry), I think most of its teachings apply to textbooks and other materials to study in an academic sense.\nThis is the first in a series of posts detailing how I study hard materials and try to extract the most knowledge from them."
  },
  {
    "objectID": "post/inspectional/index.html#studying-in-stages",
    "href": "post/inspectional/index.html#studying-in-stages",
    "title": "Stages of studying: 1 - Inspectional Reading",
    "section": "Studying in stages",
    "text": "Studying in stages\nThe basic premise of the book, and something that I apply to almost everything I read, is that reading or studying should be done in stages. I felt quite at home when Adler and van Doren talk about the classic error of trying to read a difficult book, stumping into the first hard concept, and then being stuck for hours in the same chapter - without even understanding what the book is about. Depending on the book level, you will not understand it in the first reading.\nHence, when you have anything to read in front of you, the first step is to do an Inspectional Reading - a high-level form of reading, aiming for general concepts and the overall structure of the book or document, without wasting time on details."
  },
  {
    "objectID": "post/inspectional/index.html#what-to-look-when-inspectional-reading",
    "href": "post/inspectional/index.html#what-to-look-when-inspectional-reading",
    "title": "Stages of studying: 1 - Inspectional Reading",
    "section": "What to look when inspectional reading",
    "text": "What to look when inspectional reading\nThe authors of How to Read a Book make it clear: inspectional reading is active and demand you take notes. Lately I’ve been a fan of taking notes in paper notebooks:\n\n\n\nPhoto of a notebook with notes titles “Inspectional Reading”\n\n\nNotice above what I noted: the overall structure of a Heat Transfer book I was studying, the main themes threated, some comments on the notation used, the main equations that grabbed my attention, and then some tasks to delve deeper.\nWhen I was reading the material above, did I encounter some concepts that I did not understand? Of course! But I did not let it stop me of skimming through the whole book. I was actually looking for some details about differential equations, and I have to say I do not understand them yet – but I do know that this book has some answers, and I know where to look. I need another deep work session to do an analytical reading - subject of another post."
  },
  {
    "objectID": "post/inspectional/index.html#time-constraints",
    "href": "post/inspectional/index.html#time-constraints",
    "title": "Stages of studying: 1 - Inspectional Reading",
    "section": "Time constraints",
    "text": "Time constraints\nIt is fundamental that an inspectional reading is time bounded - an hour, at most. The purpose of this stage is to get answers quickly and not waste time\nHere is another example when I was studying some old class notes:\n\n\n\nPhoto of notebook with notes\n\n\nI was examining these class notes because my father made me take all of my old college notebooks from his home, and while studying the Heat Transfer book I remember of a Linear Systems class that I took in college.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView this post on Instagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA post shared by Fábio P. Fortkamp, Dr. Eng. | Mechanical Engineer (@fpfortkamp)\n\n\n\n\nI thought studying these notes might be useful for my projects - but as I completed my Inspectional Reading, I realized this material was not right (for now). I did not have to read two chapters in detail, which would take much more time, to reach that conclusion."
  },
  {
    "objectID": "post/inspectional/index.html#the-other-stages",
    "href": "post/inspectional/index.html#the-other-stages",
    "title": "Stages of studying: 1 - Inspectional Reading",
    "section": "The other stages",
    "text": "The other stages\nStudying is deeply important to me as a researcher, and I treat it seriously. I can only advance in my carrer if I have impactful ideas.\nStay tuned for more posts of my study techniques and tips…"
  },
  {
    "objectID": "post/starship/index.html",
    "href": "post/starship/index.html",
    "title": "Higher productivity for developers with Starship",
    "section": "",
    "text": "If you follow the internet trends around tools for developers, you might have heard of Starship, a tool that gives useful information quickly for higher productivity for developers.\nAt first, I got the feeling that Startship is more cosmetic than anything else, but after a few weeks working with it, I noticed that it is indeed a productivity tool in the original sense: low effort, high speed gains in the day-to-day workflow."
  },
  {
    "objectID": "post/starship/index.html#a-typical-problem-that-starship-solves",
    "href": "post/starship/index.html#a-typical-problem-that-starship-solves",
    "title": "Higher productivity for developers with Starship",
    "section": "A typical problem that Starship solves",
    "text": "A typical problem that Starship solves\nBy day, I write mostly Python code, and the tricky thing that people forget is that there is no Python - there are Pythons. Each new Python 3.X version introduces several new features and might break some APIs from other 3.X versions. If I write code for Python 3.12, colleagues of mine that not so tech-savy and have only Python 3.10 in their machines would not be able to use my tools.\nA similar problem occur for package versions: different clients use different versions of my company’s products, so when debugging I need to be sure of running the correct version.\nEnter Starship. When prototyping an application this morning, this is the prompt I got:\n~/newapp on  main [?] is 📦 v0.1.0 via 🐍 v3.11.8 took 4s\n➜\nThis tells me immediately that:\n\nI’m on the newapp root directory\nI’m on the main branch\nThere is at least one untracked file in git\nThe package version 0.1.0\nI’m not in an activated virtual environment, but am running Python 3.11.8\nThe previous command tool 4 seconds to run\n\nEverything substantial that I would do, like activating an environment or bumping up the package version, would reflect immediately in the prompt.\nWhen I switch projects to use Go for a new CLI tool that I’m building, now I see this:\n~/awesome-go-cli on  main via 🐹 v1.21.6\nand now my brain notices the new animal and knows that I need to think statically-typed."
  },
  {
    "objectID": "post/starship/index.html#productivity-for-developers-easy-to-setup-powerful-results",
    "href": "post/starship/index.html#productivity-for-developers-easy-to-setup-powerful-results",
    "title": "Higher productivity for developers with Starship",
    "section": "Productivity for developers: easy to setup, powerful results",
    "text": "Productivity for developers: easy to setup, powerful results\nOf course real nerds would set it up with shell variables in the profile and RC files. The real productivity leap is that configuration is minimal:\n\nInstall Starship with the official guide\nCreate your configuration in ~/.config/starship.toml. Everything you saw above is built-in: there is the entirety of my configuration with comments:\n\n# Replace the '❯' symbol in the prompt with '➜'\n[character] # The name of the module we are configuring is 'character'\n# The 'success_symbol' segment is being set to '➜' with the color 'bold green'\nsuccess_symbol = '[➜](bold green)'\nerror_symbol = '[➜](bold red)'\n\n\n[c]\nsymbol = \" \"\n\n[directory]\n# the default is to truncate the full path in the prompt\n# this increases the number of subdirectories before truncation happens\nread_only = \" 󰌾\"\ntruncation_length = 6\ntruncation_symbol = \"...\"\ntruncate_to_repo = false\n\n\n[docker_context]\n# I rarely use Docker but when I do, I find the Docker additions distracting\ndisabled = true\nThe TOML file is based on modules that you customize individually. Notice I did not have to change nor the Python nor the Go modules.\nDo you use any shell prompt like this? Leave suggestions for similar productivity tools in the comments!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there. I’m Dr. Fábio P. Fortkamp, I scientific software developer from southern Brazil.and in this blog I write about solving real Mechanical Engineering problems with Python, R, and other cool computational tools and apps."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education:",
    "text": "Education:\nDoctorate (Dr. Eng.) in Mechanical Engineering Federal University of Santa Catarina, 2019\nMaster’s (M. Eng.) in Mechanical Engineering Federal University of Santa Catarina, 2014\nBachelor in Mechanical Engineering Federal University of Santa Catarina, 2012"
  },
  {
    "objectID": "about.html#research-and-professional-interests",
    "href": "about.html#research-and-professional-interests",
    "title": "About",
    "section": "Research and professional interests",
    "text": "Research and professional interests\n\nMagnetocaloric Refrigeration\nMachine Learning\nMixture Thermodynamics\nMultiphysics Problems\nMultiphase Heat Transfer"
  },
  {
    "objectID": "post/py27/index.html",
    "href": "post/py27/index.html",
    "title": "How to maintain a codebase compatible with Python 2 and 3 at the same time using tox",
    "section": "",
    "text": "Python 2.7 is still used. This is neither a judgement, nor an opinion, but a statement. As I’m writing this, I’ve been regularly deploying software to a server that only has Python 2.7 installed for a whole year. I have no control over the server, and my client is one of the largest companies in Brazil. Everything works fine. Like I said: Python 2.7 is still used.\nSince I have two small kids, I try to be pragmatic and not waste (too much) time complaining about this, instead focusing on how I can make my life easier. It turns out, if you look around a little bit longer, you can find ways to work with older versions Python more smoothly. And the final touch: you make a Python codebase compatible with Python 2 and 3, allowing you to use and test your project using more modern tools while making sure nothing brakes if someone else keeps using legacy software.\nThe secret is to use tox environments. This tool just keeps amazing me. Here’s the tox.ini file that I use for one of my projects, that is based on Python 2 but is being planned to upgrade to a newer server with newer versions of Python:\n[tox]\nenv_list =\n    format\n    lint\n    py{27,37,38,39,310,312}\nrequires = virtualenv&lt;20.22.0\n\n[testenv]\ndescription = run the tests with pytest\ndeps = \n    pytest\ncommands =\n    pytest {tty:--color=yes} -xvv --ff {posargs}\n\n[testenv:format]\nbase_python=python2.7\ndescription = format code\ndeps = \n    autopep8 &lt; 1.6\ncommands=\n    autopep8 --in-place src tests\n\n[testenv:lint]\nbase_python=python2.7\ndescription = lint code\ndeps = \n    flake8==3.9.2\n    pydocstyle\ncommands = \n    flake8 {posargs:src tests}\n    pydocstyle {posargs:src tests}\nThis assumes you have interpreters python2.7, python3.7 etc available in your path. I like to use asdf, but the cool kids seem to be using mise nowadays.\nHow this works: running tox -e lint in the project root, where tox.ini is placed, will lint the files under the src and tests folders using a version of flake8 and pydocstyle that is compatible with Python 2 (specified in the base_python key). The same applies for tox -e format. All these tools will point out errors like unused variables, missing docstrings, large complexity etc. Since it is based in Python 2, it will not complain about deprecated syntax. For full transparency, here is a .flake8 file that I put in the project directory:\n[flake8]\nselect = B,B9,BLK,C,E,F,W,I\nignore = E203,E501,W503\nmax-line-length = 80\nmax-complexity = 10\nimport-order-style = google\nIf I want to format or lint specific files, I can specify them as such:\ntox -e lint -- src/main.py\nEverything after the -- in a tox invocation is inserted into posargs in each tox environment, which in the example above have the default values of src tests, if no argument is passed.\nNow for the cross-version part: the default environment, with no suffix after the :, runs pytest, and I can choose the desired version using a shortcut tox syntax. Running tox -e py27 will run tests under Python 2.7, tox -e py311 under Python 3.11, and so on. The first time you run each environment, tox creates a virtual environent based on the specified version, installs the most recent version of pytest compatible with that release, and then run the tests. Subsequent calls will reuse the environment under the .tox folder, unless you pass the -r flag to recreate the environment.\nThe tox tool is essentially a virtual environment manager, and is installed using a modern version of Python (I install it using pipx). The virtualenv-related requires line in tox.ini is what makes it possible, by constraining the version of virtualenv that is capable of working with Python 2.7 environments.\nThe final cherry on the cake: running tox p will run all environments specified in env_list in parallel mode. In my old laptop, I had tests run for all specified versions, plus linting and formatting for Python 2.7 compatibility, under 1 hour (my test suite needs an urgent optimization). After a development session, if I run:\ntox -e format,lint,py27,py312\nI get the code formated, linted, and tests under two major Python versions. If I just did brakes something, I get immediate feedback and then iterate until making all tests pass. I like to run this in serial mode (with the p argument) to make sure the formatter doesn’t break anything; I supposed I could run something like this to be faster:\ntox -e format,lint\ntox p py27,py312\nBefore integrating my changes into a main branch to be submitted to a Pull Request, I like to run the entire test suite to be safer.\ntox completely changed my view of working with Python. I`ll talk a lot more about it in future posts."
  }
]